{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radio-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Working on patient number 0 #########\n",
      "####### Working on patient number 1 #########\n",
      "####### Working on patient number 2 #########\n",
      "####### Working on patient number 3 #########\n",
      "####### Working on patient number 4 #########\n",
      "####### Working on patient number 5 #########\n",
      "####### Working on patient number 6 #########\n",
      "####### Working on patient number 7 #########\n",
      "####### Working on patient number 8 #########\n",
      "####### Working on patient number 9 #########\n",
      "####### Working on patient number 10 #########\n",
      "####### Working on patient number 11 #########\n",
      "####### Working on patient number 12 #########\n",
      "####### Working on patient number 13 #########\n",
      "####### Working on patient number 14 #########\n",
      "####### Working on patient number 15 #########\n",
      "####### Working on patient number 16 #########\n",
      "####### Working on patient number 17 #########\n",
      "####### Working on patient number 18 #########\n",
      "####### Working on patient number 19 #########\n",
      "####### Working on patient number 20 #########\n",
      "####### Working on patient number 21 #########\n",
      "####### Working on patient number 22 #########\n",
      "####### Working on patient number 23 #########\n",
      "####### Working on patient number 24 #########\n",
      "####### Working on patient number 25 #########\n",
      "####### Working on patient number 26 #########\n",
      "####### Working on patient number 27 #########\n",
      "####### Working on patient number 28 #########\n",
      "####### Working on patient number 29 #########\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import data, util, measure, morphology\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn import preprocessing as pre\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#WORK_DIR=\"/home/storm/PhD_open_dataset/open_ms_data/cross_sectional/coregistered_resampled/\"\n",
    "\n",
    "WORK_DIR=\"/users/kfotso/carc-scratch/openms_dataset/coregistered_resampled\"\n",
    "\n",
    "\n",
    "# Defining the total bins and the hist feature array\n",
    "total_bins = 10\n",
    "features = np.zeros([1, total_bins])\n",
    "PATIENTS = sorted(os.listdir(WORK_DIR))\n",
    "IND = 0 \n",
    "\n",
    "# Create dictionary to retain coordinates of lesions:\n",
    "total_patients = 30\n",
    "patient_dict = dict(zip(PATIENTS, [{\"indexes\" : [], \n",
    "                                    \"cluster_types\" : [],\n",
    "                                    \"total_cluster_types\" : [] } for _ in range(total_patients) ]))\n",
    "\n",
    "for patient_num, DIR in enumerate(PATIENTS):\n",
    "    \n",
    "    print(\"####### Working on patient number {} #########\".format(patient_num ))\n",
    "    patient = os.path.join(WORK_DIR, DIR)\n",
    "\n",
    "    # Loading the FLAIR dataset\n",
    "    flair_path = os.path.join(patient, \"FLAIR_advanced_gabor_amfm_high.nii.gz\")\n",
    "    lesion_path = os.path.join(patient, \"consensus_gt.nii.gz\")\n",
    "    \n",
    "    flair_nii = nib.load(flair_path)\n",
    "    gt_nii = nib.load(lesion_path)\n",
    "    \n",
    "    # Transforming data to numpy array\n",
    "    flair_arr = flair_nii.get_fdata()\n",
    "    \n",
    "    # converting nan to num\n",
    "    flair_arr = np.nan_to_num(flair_arr)\n",
    "    \n",
    "    gt_arr = gt_nii.get_fdata().astype(bool)\n",
    "    \n",
    "    # Normalize the flair image:\n",
    "    flair_arr = (flair_arr-np.min(flair_arr))/(np.max(flair_arr)-np.min(flair_arr))\n",
    "    \n",
    "    # Preprocessing step:\n",
    "    #We clean the lesion volume of a very small lesions\n",
    "    thresh_mask = morphology.remove_small_objects(gt_arr, min_size=15) \n",
    "    label_image = measure.label(thresh_mask, connectivity=gt_arr.ndim)\n",
    "       \n",
    "    #Connected components\n",
    "    props = measure.regionprops(label_image)\n",
    "    properties = ['label', 'area', 'centroid']\n",
    "    props_table = measure.regionprops_table(label_image,\n",
    "                           properties=properties)\n",
    "    \n",
    "    data = pd.DataFrame(props_table)\n",
    "\n",
    "\n",
    "    # Get only the lesions based on the ground truth.\n",
    "    # lesion_only = flair_arr * gt_arr\n",
    "    \n",
    "    #\n",
    "    sl, x, y = flair_arr.shape\n",
    "    \n",
    "    #features = np.zeros([props_table['label'].shape[0], total_bins])\n",
    "    \n",
    "    if patient_num == 0:\n",
    "        patient_dict[DIR][\"indexes\"].append(IND)\n",
    "    else:\n",
    "        patient_dict[DIR][\"indexes\"].append(IND + 1)\n",
    "        \n",
    "    for ind in np.nditer(props_table['label']): \n",
    "        region = label_image==ind\n",
    "        lesion_only = flair_arr * region\n",
    "        \n",
    "        \n",
    "        # histogram\n",
    "        les = np.where(lesion_only > 0)\n",
    "        h, edges = np.histogram(lesion_only[les], bins=total_bins)\n",
    "        \n",
    "        # Applying kernel density\n",
    "        #h = h[:, np.newaxis]\n",
    "        #kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(h)\n",
    "        #h_kde = kde.score_samples(kde)\n",
    "        \n",
    "        if patient_num == 0 and ind ==0:\n",
    "            features[0, :] = h\n",
    "        else:        \n",
    "            features = np.vstack((features, h))\n",
    "            #features[ind -1] = h\n",
    "            \n",
    "            \n",
    "    #\n",
    "    IND += np.ndarray.item(ind)\n",
    "    patient_dict[DIR][\"indexes\"].append(IND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "published-devil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clusters are 2\n"
     ]
    }
   ],
   "source": [
    "# Clustering for all the patients    \n",
    "total_clusters = 2\n",
    "clustering = KMeans(n_clusters=total_clusters,\n",
    "                    random_state=0, n_init=\"auto\",).fit(features)\n",
    "\n",
    "# Print Clustering #\n",
    "print(\"Total clusters are {}\".format(clustering.n_clusters))\n",
    "\n",
    "for patient_ in patient_dict.keys():\n",
    "    start_ind = patient_dict[patient_][\"indexes\"][0]\n",
    "    end_ind = patient_dict[patient_][\"indexes\"][1]\n",
    "    \n",
    "    cluster_types = np.unique(clustering.labels_[start_ind:end_ind])\n",
    "    patient_dict[patient_][\"cluster_types\"] = cluster_types.tolist()\n",
    "    patient_dict[patient_][\"total_cluster_types\"] = len(cluster_types.tolist())\n",
    "\n",
    "# Converting into a dataframe and saving as csv:\n",
    "SOFTWARE_DIR = \"/users/kfotso/carc-scratch/openms_dataset/results\"\n",
    "pd_clusters = pd.DataFrame.from_dict(patient_dict)\n",
    "pd_clusters.to_csv(os.path.join(SOFTWARE_DIR, \"_knn_cluster_types_mag_high_2_clusters.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Image_processing]",
   "language": "python",
   "name": "conda-env-.conda-Image_processing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
